{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from sequemem import seqds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic string breaker \"word word2\" -> ['word', 'word2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123', 'alpha', 'alpha123', 'c/o', 'alpha', 'STREET']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def w(str_sentence):\n",
    "    return re.findall(r\"[\\w'/-:]+|[.,!?;]\", str_sentence)\n",
    "st = w(\"123 alpha alpha123 c/o alpha STREET\")\n",
    "st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder, takes a single word and returns a list of 'features' characterizing word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123', 'south', 'main', 'street', '.']\n",
      "[['DIGIT'], ['DIR', 'ALPHA'], ['ALPHA'], ['WAY', 'ALPHA'], ['PERIOD']]\n",
      "\n",
      "['1217', 'iris', 'box', '222']\n",
      "[['DIGIT'], ['ALPHA'], ['ALPHA', 'POB2'], ['DIGIT']]\n",
      "\n",
      "['1217', 'iris', 'box']\n",
      "[['DIGIT'], ['ALPHA'], ['ALPHA', 'POB2']]\n",
      "\n",
      "['po', 'box', '117']\n",
      "[['ALPHA', 'POB0'], ['ALPHA', 'POB2'], ['DIGIT']]\n",
      "\n",
      "['box', '21111470', 'la', 'cima', 'rd']\n",
      "[['ALPHA', 'POB2'], ['DIGIT'], ['ALPHA', 'PRON'], ['ALPHA'], ['WAY', 'ALPHA']]\n",
      "\n",
      "['1217', 'iris', 'court', 'c/o', 'stewy', 'dewy']\n",
      "[['DIGIT'], ['ALPHA'], ['WAY', 'ALPHA'], ['DELEG'], ['ALPHA'], ['ALPHA']]\n",
      "\n",
      "['1215', 'iris', 'court', 'c/o', 'stewy']\n",
      "[['DIGIT'], ['ALPHA'], ['WAY', 'ALPHA'], ['DELEG'], ['ALPHA']]\n",
      "\n",
      "['123', 'elcrest', 'hwy']\n",
      "[['DIGIT'], ['ALPHA'], ['WAY', 'ALPHA']]\n",
      "\n",
      "['2323', 'elmhurst', 'way']\n",
      "[['DIGIT'], ['ALPHA'], ['WAY', 'ALPHA']]\n",
      "\n",
      "['2323', 'way', 'elmhurst']\n",
      "[['DIGIT'], ['WAY', 'ALPHA'], ['ALPHA']]\n",
      "\n",
      "['c/o', 'frank', '123', 'south', 'main', 'st', '.']\n",
      "[['DELEG'], ['ALPHA'], ['DIGIT'], ['DIR', 'ALPHA'], ['ALPHA'], ['WAY', 'PRE', 'ALPHA'], ['PERIOD']]\n",
      "\n",
      "['123', 'main', 'st', '.', 'attn:', 'elmer', 'fudge']\n",
      "[['DIGIT'], ['ALPHA'], ['WAY', 'PRE', 'ALPHA'], ['PERIOD'], ['DELEG'], ['ALPHA'], ['ALPHA']]\n",
      "\n",
      "['333', 'st', 'james', 'st']\n",
      "[['DIGIT'], ['WAY', 'PRE', 'ALPHA'], ['ALPHA'], ['WAY', 'PRE', 'ALPHA']]\n",
      "\n",
      "['c/o', 'forever', '21', '111', 'south', 'broadway']\n",
      "[['DELEG'], ['ALPHA'], ['DIGIT'], ['DIGIT'], ['DIR', 'ALPHA'], ['ALPHA']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def encoder(word):\n",
    "    encodings = {\n",
    "        'ALPHA': [r'^[a-z]+$'],\n",
    "        'DIGIT': [r'^\\d+$'],\n",
    "        'ALNUM': [r'^(\\d+[a-z]+|[a-z]+\\d+)[\\da-z]*$'],\n",
    "        'COMMA': [r'^,$'],\n",
    "        'PERIOD': [r'^\\.$'],\n",
    "        'WAY': [r'^street$', r'^st$',r'^road$',r'^rd$', r'^ave$',r'^avenue$',r'^hwy$', r'^highway$', r'^ct$', r'^court$', r'^way$'],\n",
    "        'DELEG': [r'^attn$', r'^attn:$', r'^c\\/o$', r'^co$' ],\n",
    "        'POB0': [r'^po$', r'^p\\.o\\.$'],\n",
    "        'POB2': [r'^box$'],\n",
    "        'DIR':  [r'^east$',r'^west$',r'^north$',r'^south$',],\n",
    "        'PRE':  [r'^st$'],\n",
    "        'PRON': [r'^el$',r'^la$',r'^las$',r'^los$'],\n",
    "        'ADDRESS': [r'^:adr$'],\n",
    "        'POBOX': [r'^:box$'],\n",
    "        'ATTN': [r'^:deleg$']\n",
    "    \n",
    "    }\n",
    "    hits = []\n",
    "    for key, rexs in encodings.items():\n",
    "        for rex in rexs:\n",
    "            if re.match(rex, word):\n",
    "                hits.append(key)\n",
    "    return hits\n",
    "\n",
    "\n",
    "addresses = [\n",
    "    '123 south main street.',\n",
    "    '1217 iris box 222',\n",
    "    '1217 iris box',\n",
    "    'po box 117',\n",
    "    'box 2111'\n",
    "    '1470 la cima rd',\n",
    "    '1217 iris court c/o stewy dewy',\n",
    "    '1215 iris court c/o stewy',\n",
    "    '123 elcrest hwy',\n",
    "    '2323 elmhurst way',\n",
    "    '2323 way elmhurst',\n",
    "    'c/o frank 123 south main st.',\n",
    "    '123 main st. attn: elmer fudge',\n",
    "    '333 st james st',\n",
    "    'c/o forever 21 111 south broadway'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for address in addresses:\n",
    "    print(w(address))\n",
    "    print([encoder(word) for word in w(address)])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The lexicon and get_normalized fn determine how to intepret a word.\n",
    "* So for example, 'st', can mean 'saint', or 'street', depending if we look at it in the context of 'pre'(prefix) or 'way' as in a street or road designation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saint\n",
      "street\n"
     ]
    }
   ],
   "source": [
    "lexicon = {\n",
    "    'WAY': {\n",
    "        'street': ['st', 'street'],\n",
    "        'road':  ['rd', 'road'],\n",
    "        'avenue': ['ave', 'avenue'],\n",
    "        'court': ['ct']\n",
    "        },\n",
    "    'PRE': {\n",
    "        'saint': ['st']\n",
    "        },\n",
    "    'ADDRESS': {\n",
    "        ':adr'\n",
    "        },\n",
    "    'POBOX': {\n",
    "        ':box'\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_normalized(word, _way, lexicon):\n",
    "    for entry, lst_matches in lexicon[_way].items():\n",
    "        if word in lst_matches:\n",
    "            return entry\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "print(get_normalized('st', 'PRE', lexicon))\n",
    "print(get_normalized('st', 'WAY', lexicon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps...\n",
    "* Combine encoded sentence with a predetermined pattern, say like expecting 'way' type of words at end and see if we can reliably interpret the meaning of abbrevs like st.\n",
    "* Automate geneation of the address templates by running encoder on a looooong list of valid addresses\n",
    "* Hopefully after that an address can be normalized reliably... and this can then be applied maybe to business names....\n",
    "\n",
    "* and IF that works, ^^, then do it for 'c/o', 'attn:', and 'po box' phrases... and the write more code to break up a long sentence into its composite phrases.  So like \"some very long string with lots of words\" => \"c/o substring\" + \"valid address\" + \"junk on end\".....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(seq, sts):\n",
    "    return seq.predict(['|'.join(encoder(word)) for word in w(sts)]).sdr_predicted\n",
    "def train_arr(seq, arr_w):\n",
    "    return seq.predict(['|'.join(encoder(word)) for word in arr_w]).sdr_predicted\n",
    "def think(seq, sts):\n",
    "    return seq.predict(['|'.join(encoder(word)) for word in w(sts)], is_learning=False).sdr_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid: input\n",
       "n_init: <node: <start>>\n",
       "predicted: []\n",
       "active: [<node: ADDRESS>]\n",
       "sdr_active: ['DIGIT DIR|ALPHA ALPHA WAY|PRE|ALPHA ADDRESS']\n",
       "sdr_predicted: []"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = seqds.Seqds('input')\n",
    "test_st = \"123 east main st\" \" :adr\"\n",
    "seq.predict(['|'.join(encoder(word)) for word in w(test_st)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid: input\n",
       "n_init: <node: <start>>\n",
       "predicted: []\n",
       "active: [<node: ADDRESS>]\n",
       "sdr_active: ['DIGIT ALPHA WAY|ALPHA ADDRESS']\n",
       "sdr_predicted: []"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_st = \"1217 iris ct\" \" :adr\"\n",
    "seq.predict(['|'.join(encoder(word)) for word in w(test_st)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid addresses \n",
    "train_samples = [\n",
    "    \"123 main st\",\n",
    "    \"1217 iris ct\",\n",
    "    \"123 east main st\",\n",
    "    \"123 south main street.\",\n",
    "    \"90 south park rd\",\n",
    "    \"987 el canyon ave\",\n",
    "    \"333 st james st\",\n",
    "    \"123 west hill\",\n",
    "    \"77 el camino real\"\n",
    "]\n",
    "for ts in train_samples:\n",
    "    train(seq, \"{} {}\".format(ts,\":adr\"))\n",
    "\n",
    "# valid po box\n",
    "train_samples = [\n",
    "    \"po box 1234\",\n",
    "    \"box 999\"\n",
    "]\n",
    "for ts in train_samples:\n",
    "    train(seq, \"{} {}\".format(ts,\":box\"))\n",
    "\n",
    "# valid attn\n",
    "train_samples = [\n",
    "    \"c/o john smith\",\n",
    "    \"attn john smith\",\n",
    "    \"attn: john smith\",\n",
    "    \"c/o john\"\n",
    "]\n",
    "for ts in train_samples:\n",
    "    train(seq, \"{} {}\".format(ts,\":deleg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADDRESS', 'ALPHA|POB0', 'DELEG']\n",
      "['ADDRESS', 'ALPHA|POB0', 'DELEG']\n",
      "['POBOX']\n"
     ]
    }
   ],
   "source": [
    "print(train(seq, \"1217 iris ct\"))\n",
    "print(train_arr(seq, [\"1217\", \"iris\", \"ct\"]))\n",
    "print(train_arr(seq, [\"po\", \"box\", \"7001\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADDRESS'] \t\t 123 south main street.\n",
      "[] \t\t 1217 iris box 222\n",
      "['DIGIT'] \t\t 1217 iris box\n",
      "['POBOX'] \t\t po box 117\n",
      "[] \t\t box 21111470 la cima rd\n",
      "[] \t\t 1217 iris court c/o stewy dewy\n",
      "['ALPHA'] \t\t 1215 iris court c/o stewy\n",
      "['ADDRESS', 'ALPHA|POB0', 'DELEG'] \t\t 123 elcrest hwy\n",
      "['ADDRESS', 'ALPHA|POB0', 'DELEG'] \t\t 2323 elmhurst way\n",
      "[] \t\t 2323 way elmhurst\n",
      "[] \t\t c/o frank 123 south main st.\n",
      "[] \t\t 123 main st. attn: elmer fudge\n",
      "['ADDRESS'] \t\t 333 st james st\n",
      "[] \t\t c/o forever 21 111 south broadway\n"
     ]
    }
   ],
   "source": [
    "valid_addresses = [\n",
    "    \"666 demons st\",\n",
    "    \"999 devils ct\"\n",
    "]\n",
    "\n",
    "for va in addresses:\n",
    "    print(train(seq, va), \"\\t\\t\", va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_address(seq, arr_st):\n",
    "    \"\"\"Is this passed sequence a valid address?\"\"\"\n",
    "    return any([pred == 'ADDRESS' for pred in train_arr(seq, arr_st)]) \n",
    "    \n",
    "sent = \"1217 iris court c/o stewy dewy\"\n",
    "assert is_address(seq, w(sent)) == False\n",
    "assert is_address(seq, w(\"1217 iris ct\")) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pobox(seq, arr_st):\n",
    "    \"\"\"Is this passed sequence a valid address?\"\"\"\n",
    "    assert isinstance(arr_st, list)\n",
    "    return any([pred == 'POBOX' for pred in train_arr(seq, arr_st)])\n",
    "\n",
    "sent = \"po box 7001\"\n",
    "assert is_pobox(seq, w(sent)) == True\n",
    "\n",
    "def is_deleg(seq, arr_st):\n",
    "    \"\"\"Is this passed sequence a valid address?\"\"\"\n",
    "    assert isinstance(arr_st, list)\n",
    "    return any([pred == 'ATTN' for pred in train_arr(seq, arr_st)])\n",
    "\n",
    "sent = \"attn john doe\"\n",
    "assert is_deleg(seq, w(sent)) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  attn jon doe 1217 iris ct po box 7001\n",
      "0 2 ATTN ['attn', 'jon', 'doe']\n",
      "3 5 ADDRESS ['1217', 'iris', 'ct']\n",
      "6 8 POBOX ['po', 'box', '7001']\n",
      "7 8 POBOX ['box', '7001']\n"
     ]
    }
   ],
   "source": [
    "def chunk_sentence_array(seq, sent):\n",
    "    \"\"\"Return chunked identified substrings is possible\"\"\"\n",
    "    print(\"Processing: \", sent)\n",
    "    arr_w = w(sent)\n",
    "    idx_tail = len(arr_w)\n",
    "    for idx_beg in range(idx_tail):\n",
    "        for idx_end in range(idx_beg + 1, idx_tail +1):\n",
    "            if is_address(seq, arr_w[idx_beg:idx_end]):\n",
    "                print(idx_beg, idx_end - 1,'ADDRESS', arr_w[idx_beg:idx_end])\n",
    "            if is_pobox(seq, arr_w[idx_beg:idx_end]):\n",
    "                print(idx_beg, idx_end - 1, 'POBOX', arr_w[idx_beg:idx_end])\n",
    "            if is_deleg(seq, arr_w[idx_beg:idx_end]):\n",
    "                print(idx_beg, idx_end - 1, 'ATTN', arr_w[idx_beg:idx_end])\n",
    "                \n",
    "chunk_sentence_array(seq, \"attn jon doe 1217 iris ct po box 7001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing:  123 south main street.\n",
      "0 2 ADDRESS ['123', 'south', 'main']\n",
      "0 3 ADDRESS ['123', 'south', 'main', 'street']\n",
      "0 4 ADDRESS ['123', 'south', 'main', 'street', '.']\n",
      "\n",
      "Processing:  1217 iris box 222\n",
      "2 3 POBOX ['box', '222']\n",
      "\n",
      "Processing:  1217 iris box\n",
      "\n",
      "Processing:  po box 117\n",
      "0 2 POBOX ['po', 'box', '117']\n",
      "1 2 POBOX ['box', '117']\n",
      "\n",
      "Processing:  box 21111470 la cima rd\n",
      "0 1 POBOX ['box', '21111470']\n",
      "1 4 ADDRESS ['21111470', 'la', 'cima', 'rd']\n",
      "\n",
      "Processing:  1217 iris court c/o stewy dewy\n",
      "0 2 ADDRESS ['1217', 'iris', 'court']\n",
      "3 4 ATTN ['c/o', 'stewy']\n",
      "3 5 ATTN ['c/o', 'stewy', 'dewy']\n",
      "\n",
      "Processing:  1215 iris court c/o stewy\n",
      "0 2 ADDRESS ['1215', 'iris', 'court']\n",
      "3 4 ATTN ['c/o', 'stewy']\n",
      "\n",
      "Processing:  123 elcrest hwy\n",
      "0 2 ADDRESS ['123', 'elcrest', 'hwy']\n",
      "\n",
      "Processing:  2323 elmhurst way\n",
      "0 2 ADDRESS ['2323', 'elmhurst', 'way']\n",
      "\n",
      "Processing:  2323 way elmhurst\n",
      "\n",
      "Processing:  c/o frank 123 south main st.\n",
      "0 1 ATTN ['c/o', 'frank']\n",
      "2 4 ADDRESS ['123', 'south', 'main']\n",
      "2 5 ADDRESS ['123', 'south', 'main', 'st']\n",
      "\n",
      "Processing:  123 main st. attn: elmer fudge\n",
      "0 2 ADDRESS ['123', 'main', 'st']\n",
      "4 5 ATTN ['attn:', 'elmer']\n",
      "4 6 ATTN ['attn:', 'elmer', 'fudge']\n",
      "\n",
      "Processing:  333 st james st\n",
      "0 3 ADDRESS ['333', 'st', 'james', 'st']\n",
      "\n",
      "Processing:  c/o forever 21 111 south broadway\n",
      "0 1 ATTN ['c/o', 'forever']\n",
      "3 5 ADDRESS ['111', 'south', 'broadway']\n"
     ]
    }
   ],
   "source": [
    "for address in addresses:\n",
    "    print()\n",
    "    chunk_sentence_array(seq, address)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from sequemem import seqds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic string breaker \"word word2\" -> ['word', 'word2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123', 'alpha', 'alpha123', 'c/o', 'alpha', 'STREET']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def w(str_sentence):\n",
    "    return re.findall(r\"[\\w'/-:]+|[.,!?;]\", str_sentence)\n",
    "st = w(\"123 alpha alpha123 c/o alpha STREET\")\n",
    "st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder, takes a single word and returns a list of 'features' characterizing word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123', 'south', 'main', 'street', '.']\n",
      "[['digit'], ['alpha', 'dir'], ['alpha'], ['alpha', 'way'], ['period']]\n",
      "\n",
      "['1217', 'iris', 'box', '222']\n",
      "[['digit'], ['alpha'], ['alpha', 'pob2'], ['digit']]\n",
      "\n",
      "['1217', 'iris', 'box']\n",
      "[['digit'], ['alpha'], ['alpha', 'pob2']]\n",
      "\n",
      "['po', 'box', '117']\n",
      "[['alpha', 'pob0'], ['alpha', 'pob2'], ['digit']]\n",
      "\n",
      "['box', '21111470', 'la', 'cima', 'rd']\n",
      "[['alpha', 'pob2'], ['digit'], ['alpha', 'prnn'], ['alpha'], ['alpha', 'way']]\n",
      "\n",
      "['1217', 'iris', 'court', 'c/o', 'stewy', 'dewy']\n",
      "[['digit'], ['alpha'], ['alpha'], ['deleg'], ['alpha'], ['alpha']]\n",
      "\n",
      "['1215', 'iris', 'court', 'c/o', 'stewy']\n",
      "[['digit'], ['alpha'], ['alpha'], ['deleg'], ['alpha']]\n",
      "\n",
      "['123', 'elcrest', 'hwy']\n",
      "[['digit'], ['alpha'], ['alpha', 'way']]\n",
      "\n",
      "['2323', 'elmhurst', 'way']\n",
      "[['digit'], ['alpha'], ['alpha', 'way']]\n",
      "\n",
      "['2323', 'way', 'elmhurst']\n",
      "[['digit'], ['alpha', 'way'], ['alpha']]\n",
      "\n",
      "['c/o', 'frank', '123', 'south', 'main', 'st', '.']\n",
      "[['deleg'], ['alpha'], ['digit'], ['alpha', 'dir'], ['alpha'], ['alpha', 'way', 'pre'], ['period']]\n",
      "\n",
      "['123', 'main', 'st', '.', 'attn:', 'elmer', 'fudge']\n",
      "[['digit'], ['alpha'], ['alpha', 'way', 'pre'], ['period'], ['deleg'], ['alpha'], ['alpha']]\n",
      "\n",
      "['333', 'st', 'james', 'st']\n",
      "[['digit'], ['alpha', 'way', 'pre'], ['alpha'], ['alpha', 'way', 'pre']]\n",
      "\n",
      "['c/o', 'forever', '21', '111', 'south', 'broadway']\n",
      "[['deleg'], ['alpha'], ['digit'], ['digit'], ['alpha', 'dir'], ['alpha']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def encoder(word):\n",
    "    encodings = {\n",
    "        'alpha': [r'^[a-z]+$'],\n",
    "        'digit': [r'^\\d+$'],\n",
    "        'alnum': [r'^(\\d+[a-z]+|[a-z]+\\d+)[\\da-z]*$'],\n",
    "        'comma': [r'^,$'],\n",
    "        'period': [r'^\\.$'],\n",
    "        'way': [r'^street$', r'^st$',r'^road$',r'^rd$', r'^ave$',r'^avenue$',r'^hwy$', r'^highway$', r'^ct$', r'^way$'],\n",
    "        'deleg': [r'^attn$', r'^attn:$', r'^c\\/o$', r'^co$' ],\n",
    "        'pob0': [r'^po$', r'^p\\.o\\.$'],\n",
    "        'pob2': [r'^box$'],\n",
    "        'dir':  [r'^east$',r'^west$',r'^north$',r'^south$',],\n",
    "        'pre':  [r'^st$'],\n",
    "        'prnn': [r'^el$',r'^la$',r'^las$',r'^los$'],\n",
    "        'ADRESS': [r'^:adr$'],\n",
    "        'POBOX': [r'^:box$']\n",
    "    \n",
    "    }\n",
    "    hits = []\n",
    "    for key, rexs in encodings.items():\n",
    "        for rex in rexs:\n",
    "            if re.match(rex, word):\n",
    "                hits.append(key)\n",
    "    return hits\n",
    "\n",
    "addresses = [\n",
    "    '123 south main street.',\n",
    "    '1217 iris box 222',\n",
    "    '1217 iris box',\n",
    "    'po box 117',\n",
    "    'box 2111'\n",
    "    '1470 la cima rd',\n",
    "    '1217 iris court c/o stewy dewy',\n",
    "    '1215 iris court c/o stewy',\n",
    "    '123 elcrest hwy',\n",
    "    '2323 elmhurst way',\n",
    "    '2323 way elmhurst',\n",
    "    'c/o frank 123 south main st.',\n",
    "    '123 main st. attn: elmer fudge',\n",
    "    '333 st james st',\n",
    "    'c/o forever 21 111 south broadway'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for address in addresses:\n",
    "    print(w(address))\n",
    "    print([encoder(word) for word in w(address)])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The lexicon and get_normalized fn determine how to intepret a word.\n",
    "* So for example, 'st', can mean 'saint', or 'street', depending if we look at it in the context of 'pre'(prefix) or 'way' as in a street or road designation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saint\n",
      "street\n"
     ]
    }
   ],
   "source": [
    "lexicon = {\n",
    "        'way': {\n",
    "            'street': ['st', 'street'],\n",
    "            'road':  ['rd', 'road'],\n",
    "            'avenue': ['ave', 'avenue'],\n",
    "            'court': ['ct']\n",
    "            },\n",
    "        'pre': {\n",
    "            'saint': ['st']\n",
    "            },\n",
    "        'ADR': {\n",
    "            ':adr'\n",
    "        },\n",
    "    'POBOX': {\n",
    "        ':box'\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_normalized(word, _way, lexicon):\n",
    "    for entry, lst_matches in lexicon[_way].items():\n",
    "        if word in lst_matches:\n",
    "            return entry\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "print(get_normalized('st', 'pre', lexicon))\n",
    "print(get_normalized('st', 'way', lexicon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps...\n",
    "* Combine encoded sentence with a predetermined pattern, say like expecting 'way' type of words at end and see if we can reliably interpret the meaning of abbrevs like st.\n",
    "* Automate geneation of the address templates by running encoder on a looooong list of valid addresses\n",
    "* Hopefully after that an address can be normalized reliably... and this can then be applied maybe to business names....\n",
    "\n",
    "* and IF that works, ^^, then do it for 'c/o', 'attn:', and 'po box' phrases... and the write more code to break up a long sentence into its composite phrases.  So like \"some very long string with lots of words\" => \"c/o substring\" + \"valid address\" + \"junk on end\".....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(seq, sts):\n",
    "    return seq.predict(['|'.join(encoder(word)) for word in w(sts)]).sdr_predicted\n",
    "def think(seq, sts):\n",
    "    return seq.predict(['|'.join(encoder(word)) for word in w(sts)], is_learning=False).sdr_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid: input\n",
       "n_init: <node: <start>>\n",
       "predicted: []\n",
       "active: [<node: ADRESS>]\n",
       "sdr_active: ['digit alpha|dir alpha alpha|way|pre ADRESS']\n",
       "sdr_predicted: []"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = seqds.Seqds('input')\n",
    "test_st = \"123 east main st\" \" :adr\"\n",
    "seq.predict(['|'.join(encoder(word)) for word in w(test_st)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid: input\n",
       "n_init: <node: <start>>\n",
       "predicted: []\n",
       "active: [<node: ADRESS>]\n",
       "sdr_active: ['digit alpha alpha|way ADRESS']\n",
       "sdr_predicted: []"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_st = \"1217 iris ct\" \" :adr\"\n",
    "seq.predict(['|'.join(encoder(word)) for word in w(test_st)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = [\n",
    "    \"123 main st\",\n",
    "    \"1217 iris ct\",\n",
    "    \"123 east main st\",\n",
    "    \"123 south main street.\",\n",
    "    \"90 south park rd\",\n",
    "    \"987 el canyon ave\"\n",
    "]\n",
    "for ts in train_samples:\n",
    "    train(seq, \"{} {}\".format(ts,\":adr\"))\n",
    "train_samples = [\n",
    "    \"po box 1234\",\n",
    "    \"box 999\"\n",
    "]\n",
    "for ts in train_samples:\n",
    "    train(seq, \"{} {}\".format(ts,\":box\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADRESS']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(seq, \"1217 iris ct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADRESS'] \t\t 123 south main street.\n",
      "[] \t\t 1217 iris box 222\n",
      "['digit'] \t\t 1217 iris box\n",
      "['POBOX'] \t\t po box 117\n",
      "[] \t\t box 21111470 la cima rd\n",
      "[] \t\t 1217 iris court c/o stewy dewy\n",
      "['alpha'] \t\t 1215 iris court c/o stewy\n",
      "['ADRESS'] \t\t 123 elcrest hwy\n",
      "['ADRESS'] \t\t 2323 elmhurst way\n",
      "[] \t\t 2323 way elmhurst\n",
      "[] \t\t c/o frank 123 south main st.\n",
      "[] \t\t 123 main st. attn: elmer fudge\n",
      "[] \t\t 333 st james st\n",
      "[] \t\t c/o forever 21 111 south broadway\n"
     ]
    }
   ],
   "source": [
    "valid_addresses = [\n",
    "    \"666 demons st\",\n",
    "    \"999 devils ct\"\n",
    "]\n",
    "\n",
    "for va in addresses:\n",
    "    print(train(seq, va), \"\\t\\t\", va)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
